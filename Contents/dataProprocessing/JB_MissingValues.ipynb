{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JB_MissingValues.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNH300WzZqKZ"
      },
      "source": [
        "### 결측값 확인하기 : isnull, notnull"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmV4-I-5aEns"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "df_left = pd.DataFrame({\r\n",
        "    'KEY': ['K0', 'K1', 'K2', 'K3'],\r\n",
        "    'A': ['A0', 'A1', 'A2', 'A3'],\r\n",
        "    'B': [0.5, 2.2, 3.6, 0.4]})\r\n",
        "\r\n",
        "df_right = pd.DataFrame({\r\n",
        "    'KEY': ['K2', 'K3', 'K4', 'K5'],\r\n",
        "    'C': ['C2', 'C3', 'C4', 'C5'],\r\n",
        "    'D': ['D2', 'D3', 'D4', 'D5']})\r\n",
        "\r\n",
        "df_all = pd.merge(df_left, df_right, how='outer', on='KEY')\r\n",
        "df_all\r\n",
        "\r\n",
        "#- DataFrame 전체의 결측값 여부 확인\r\n",
        "#- df.isnull(), pd.isnull(df), df.notnull(), pd.notnull(df)\r\n",
        "#- df.isnull()과 pd.isnull(df)은 같은 의미\r\n",
        "#- df.notnull()과 pd.notnull(df)은 같은 의미\r\n",
        "\r\n",
        "pd.isnull(df_all)\r\n",
        "pd.notnull(df_all)\r\n",
        "\r\n",
        "df_all.isnull()\r\n",
        "df_all.notnull()\r\n",
        "\r\n",
        "#- 특정 변수, 특정 컬럼에 결측값 입력하기 ** 중요!\r\n",
        "#- ** string 형식인 경우에 None을 할당하면, 'None'으로 입력\r\n",
        "#- ** float 형식인 경우에 None을 할당하면,  NaN으로 자동으로 입력됨\r\n",
        "df_all.loc[[0,1], ['A', 'B']] = None\r\n",
        "df_all\r\n",
        "\r\n",
        "#- 컬럼별 결측값 개수 구하기 : df.isnull().sum()\r\n",
        "df_all.isnull().sum()\r\n",
        "\r\n",
        "#- 행단위로 결측값 개수 구하기\r\n",
        "df_all.isnull().sum(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6P9CIIQbp-u"
      },
      "source": [
        "### 결측값 연산"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od9ZT-OrijBa"
      },
      "source": [
        "df = pd.DataFrame(\r\n",
        "  np.arange(10).reshape(5, 2),\r\n",
        "  columns= ['C1', \"C2\"],\r\n",
        "  index = ['a', 'b', 'c', 'd', 'e'])\r\n",
        "\r\n",
        "df.loc[['b', 'e'], ['C1']] = None\r\n",
        "df.loc[['b', 'c'], ['C2']] = None\r\n",
        "\r\n",
        "#- 결측 존재시, sum(), cumsum() --> 결측을 제외하고 계산\r\n",
        "df.sum()\r\n",
        "df['C1'].sum()\r\n",
        "df['C1'].cumsum()\r\n",
        "\r\n",
        "#- mean(), std() 연산 시 : NaN은 분석 대상에서 제외\r\n",
        "#  --> 산술 평균이나 표준편차 값을 계산할 때, NaN이 포함된 경우는 아예 분모에서 카운트를 제외\r\n",
        "df.mean()\r\n",
        "df.std()\r\n",
        "\r\n",
        "#- DataFrame 컬럼 간 연산 시, 하나의 Row에 NaN이 하나라도 포함되어 있으면 NaN return\r\n",
        "df['C3'] = df['C1'] + df['C2']\r\n",
        "df\r\n",
        "\r\n",
        "#- DataFrame 끼리의 연산(df1 + df2) \r\n",
        "#- 같은 명의 컬럼인 경우에는 NaN을 0으로 계산하고 연산. \r\n",
        "#- 같은 명의 컬럼이 없는 경우는 모든 값을 NaN으로 연산\r\n",
        "df2 = pd.DataFrame({\r\n",
        "    'C1':[1, 1, 1, 1, 1],\r\n",
        "    'C4':[1, 1, 1, 1, 1]},\r\n",
        "    index = ['a', 'b', 'c', 'd','e'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YV0lVYUizqL"
      },
      "source": [
        "### 결측값 채우기\r\n",
        "- 결측값을 특정 값으로 채우기\r\n",
        "- 결측값을 앞 방향 또는 뒷 방향으로 채우기\r\n",
        "- 결측값 채우는 회수를 제한하기\r\n",
        "- 결측값을 특정 통계량으로 채우기\r\n",
        "- 결측값을 다른 변수의 값으로 대체하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ofS8ZYZmIFW"
      },
      "source": [
        "df = pd.DataFrame(\r\n",
        "  np.arange(15).reshape(5, 3),\r\n",
        "  columns= ['C1', \"C2\", \"C3\"])\r\n",
        "\r\n",
        "#- 결측값으로 대체하는 방법은 None으로 할당하거나, np.nan 할당\r\n",
        "df.iloc[0,0] = None\r\n",
        "df.loc[1, ['C1', 'C3']] = np.nan\r\n",
        "df.loc[2, ['C2']] = np.nan\r\n",
        "df.loc[3, ['C2']] = np.nan\r\n",
        "df.loc[4, ['C3']] = np.nan\r\n",
        "df\r\n",
        "\r\n",
        "#- (1) 결측값을 특정 값으로 채우기 : df.fillna()\r\n",
        "df_fill_zero = df.fillna(0)\r\n",
        "df_fill_zero\r\n",
        "\r\n",
        "df_fill_missing = df.fillna(\"missing\")\r\n",
        "df_fill_missing\r\n",
        "\r\n",
        "#- (2) 결측값을 앞 방향 또는 뒷 방향으로 채우기\r\n",
        "df.fillna(method = 'ffill')   #- 앞 방향\r\n",
        "df.fillna(method = 'pad')     #- 앞 방향\r\n",
        "\r\n",
        "df.fillna(method = 'bfill')     #- 뒷 방향\r\n",
        "df.fillna(method = 'backfill')  #- 뒷 방향\r\n",
        "\r\n",
        "#- 앞/뒤 방향으로 결측값 채우는 회수를 제한하기\r\n",
        "#- --> 컬럼별 데이터에서 결측값이 연속으로 생성되어 있는 부분에서 limit을 걸어서 NaN을 채울 최대 수를 지정\r\n",
        "#- limit paramter로 값 지정\r\n",
        "\r\n",
        "df.fillna(method = 'ffill', limit = 1)\r\n",
        "df.fillna(method = 'bfill', limit = 1)\r\n",
        "\r\n",
        "#- 결측값을 변수별 평균으로 대체하기 : df.where\r\n",
        "\r\n",
        "#- 컬럼에 존재하는 결측값을 컬럼별로 할당\r\n",
        "#- 하단의 두 가지 방법 사용 가능\r\n",
        "df.fillna(df.mean())\r\n",
        "df.where(df.notnull(), df.mean(), axis = 'columns')\r\n",
        "\r\n",
        "#- C1 컬럼의 평균을 가지고, (C1, C2, C3) 결측값 대체 예제\r\n",
        "df.fillna(df.mean()['C1'])\r\n",
        "\r\n",
        "#- C1, C2 컬럼만 각각 결측값 대체하고 C3는 대체 안하는 경우\r\n",
        "df.fillna(df.mean()['C1':'C2'])\r\n",
        "\r\n",
        "#- 결측값을 다른 변수의 값으로 대체하기\r\n",
        "#- C2 컬럼에 결측값이 없으면 C2 값을 그대로 사용, 있으면 C1 컬럼의 값을 가져다가 대체\r\n",
        "#- 단순 for loop를 사용하는 것 보다, np.where, pd.notnull를 사용하는 것이 훨씬 유리\r\n",
        "df['C2_New'] = np.where(pd.notnull(df['C2']) == True, df['C2'], df['C1'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5zxDDKmmaXn"
      },
      "source": [
        "### 결측값 있는 행 제거 : dropna(axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVHbOIp-DzeA"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "df = pd.DataFrame(\r\n",
        "    np.random.randn(5,4),\r\n",
        "    columns = ['C1', 'C2', 'C3', 'C4'])\r\n",
        "df.iloc[[0,1], [0]] = None\r\n",
        "df.iloc[[2], [1]] = None\r\n",
        "df_drop_row = df.dropna(axis = 0) # 행제거\r\n",
        "df_drop_col = df.dropna(axis = 1) # 열제거\r\n",
        "df['C1'].dropna() # C1 컬럼만 선택하여 열제거"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SpC0cPoE0ez"
      },
      "source": [
        "### 결측값 보간하기(interporlation of missing values)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsaUl5PGFoYc"
      },
      "source": [
        "# 시계열 데이터의 값에 선형으로 비례하는 방식으로 값을 보간(interpolate)\r\n",
        "from datetime import datetime\r\n",
        "datestrs = ['12/01/2016', '12/03/2016', '12/04/2016', '12/10/2016']\r\n",
        "datestrs = pd.to_datetime(datestrs)\r\n",
        "ts = pd.Series([1, np.nan, np.nan, 10], index = datestrs)\r\n",
        "\r\n",
        "# (1) 시계열 데이터의 값에 선형으로 비례하는 방식으로 결측값 보간\r\n",
        "ts.interpolate()\r\n",
        "ts.interpolate(method='time')  # --> method = time 지정시, index 날짜를 기준으로 linear하게 보간됨\r\n",
        "\r\n",
        "# (2) DataFrame 값에 선형으로 비례하는 방식으로 결측값 보간\r\n",
        "df = pd.DataFrame({'C1':[1, 2, np.nan, np.nan, 5], 'C2':[6, 8, 10, np.nan, 20]})\r\n",
        "df.interpolate(method = 'values')\r\n",
        "\r\n",
        "# (3) 결측값 보간 개수 제한하기 : limit\r\n",
        "ts.interpolate(method = 'time', limit = 1)\r\n",
        "df.interpolate(method = 'values', limit = 1)\r\n",
        "\r\n",
        "# (4) 보간 방향 설정하기 : limit_direction = both, forward, backward\r\n",
        "ts.interpolate(method = 'time', limit = 1, limit_direction = 'both')\r\n",
        "df.interpolate(method = 'values', limit = 1, limit_direction = 'backward')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LfgAGSV_Fo3"
      },
      "source": [
        "from datetime import datetime\r\n",
        "datestrs = ['12/01/2016', '12/03/2016', '12/04/2016', '12/10/2016']\r\n",
        "datestrs = pd.to_datetime(datestrs)\r\n",
        "ts = pd.Series([1, np.nan, np.nan, 10], index = datestrs)\r\n",
        "\r\n",
        "df = pd.DataFrame({'C1':[1, 2, np.nan, np.nan, 5], 'C2':[6, 8, 10, np.nan, 20]})\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhlLFx5AUZtw"
      },
      "source": [
        "### 결측값, 원래 값을 다른 값으로 대체하기 : replace"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5aVEyXb8JaI"
      },
      "source": [
        "## replace 와 fillna 함수는 유사한 면이 있지만,\r\n",
        "## replace 함수는 결측값이 아닌 대체값 용도로 사용이 가능하며, list, mapping dict 등으로 좀더 유연하고 포괄적으로 사용할 수 있는 장점이 있음\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "ser = pd.Series([1, 2, 3, np.nan])\r\n",
        "\r\n",
        "# (1) 결측값, 실측값으로 대체\r\n",
        "ser.replace(2, 20)\r\n",
        "ser.replace(np.nan, 20)\r\n",
        "\r\n",
        "# (2) list를 list로 대체 \r\n",
        "ser.replace([1, 2, 3, 4, np.nan], [6, 7, 8, 9, 10])\r\n",
        "\r\n",
        "# (3) mapping dict로 원래 값, 교체할 값 매핑 : replace({old1 : new1, old2 : new2})\r\n",
        "ser.replace({1:100, 2:200, 3:300, np.nan:400})\r\n",
        "\r\n",
        "# (4) DataFrame의 특정 컬럼 값 교체하기: df.replace({'col1':old_val}, {'col1':new_val})\r\n",
        "df = pd.DataFrame(\r\n",
        "    {'C1':['a_old', 'b', 'c', 'd', 'e'],\r\n",
        "     'C2':[1,2,3,4,5],\r\n",
        "     'C3':[6,7,8,9,np.nan]}\r\n",
        ")\r\n",
        "df = df.replace({'C1':'a_old'}, {'C1':'a'})\r\n",
        "df = df.replace({'C3':np.nan}, {'C3': 10})\r\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i156GF8x_EO5"
      },
      "source": [
        "### 중복값 확인 및 처리 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHOvzm9W_flr",
        "outputId": "88b44023-8f03-4a30-fc65-03c3a625dc86"
      },
      "source": [
        "import pandas as pd\r\n",
        "df = pd.DataFrame(\r\n",
        "    {'key1':['a', 'b', 'b', 'c', 'c'],\r\n",
        "     'key2':['v', 'w', 'w', 'x', 'y'],\r\n",
        "     'col':[1, 2, 3, 4, 5]}\r\n",
        ")\r\n",
        "\r\n",
        "# (1) 중복 데이터가 있는지 확인 : df.duplicated()\r\n",
        "df.duplicated(['key1'])\r\n",
        "df.duplicated(['key1', 'key2'])\r\n",
        "\r\n",
        "# (2) 중복이 있으면 처음과 끝 중 무슨 값을 남길 것인가? : keep = 'first', 'last', False\r\n",
        "# keep = 'first' --> 중복시 첫번째 값만 False, 나머지는 True\r\n",
        "# keep = 'last'  --> 중복시 마지막 값만 False, 나머지는 True\r\n",
        "# keep = False   --> 중복값 모두 True, 중복되는 행 자체를 남기지 않음\r\n",
        "df.duplicated(['key1'], keep = 'first')\r\n",
        "df.duplicated(['key1'], keep = 'last')\r\n",
        "df.duplicated(['key1'], keep = False)\r\n",
        "\r\n",
        "# (3) drop_duplicates()\r\n",
        "df.drop_duplicates(['key1'], keep = 'first')\r\n",
        "df.drop_duplicates(['key1'], keep = 'last')\r\n",
        "df.drop_duplicates(['key1'], keep =  False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    False\n",
              "1     True\n",
              "2     True\n",
              "3     True\n",
              "4     True\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    }
  ]
}